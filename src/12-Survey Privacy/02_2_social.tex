\subsection{Social}

%%Trust-ware: A Methodology to Analyze, Design, and Secure Trust and Reputation Systems
%• Policy-based vs. reputation-based: there are two main approaches to evaluate trust in the literature,
%	namely: policy-based trust management and reputation-based trust management [100]–[103].


%Stalking Online: on User Privacy in Social Networks
In online social networks,
	users are sometimes either oblivious about their privacy,
	or concerned but underestimate the privacy risks.
% A Study of Online Social Network Privacy Via the TAPE Framework
OSN service providers allow users to manage who can access which information and communication (e.g. Facebook and Google+).
Researcher studied privacy protection from two directions:

%first direction
Along the first direction,
	fundamental changes to the current design of OSN were suggested to enhance users' privacy.
Within this direction, Privacy by Design (PbD) is an important approach.
For example,
	in \cite{baden_persona_2009}, Baden et al. proposed a new type of OSNs by using \textbf{attribute-based encryption} to hide user data,
	in which symmetric keys are used to encrypt messages and only the designated friend groups can decrypt the messages.
In \cite{erkin_generating_2011},
	Erkin et al. proposed to use homomorphic encryption and \textbf{multi-party encryption techniques} to hide privacy-sensitive data from the service provider in a recommender system.

%second direction
The second direction is developing privacy protection tools based on existing OSNs.
In our work,
	we focus on both direction to deal with current and future messaging services.

In \cite{becker_measuring_2009},
	the authors propose to use the amount of information that can be inferred from social networks to quantify the privacy risks.
PrivAware detect and report unintended information disclosures through quantifying privacy risk associated with friend relationship in OSNs.
PrivAware employs inference model which is based on the fact that information about users can be inferred from their social graph.
Privacy score is calculated as total \textbf{number of attributes visible to the third party applications} divided by total number of attributes per participant.
The measured percentage is then mapped to a letter grade,
	where A score represents very few attributes being revealed and F score indicates that privacy risk to the threat of a malicious third party application is high.

%Privometer
The authors in \cite{talukder_privometer_2010} develop a tool,
	Privometer,
	to measure information leakage based on user profiles and their social graph.
The leakage is indicated by a probability numerical value.
Privometer is based on an augmented inference model where a potentially malicious application installed in the user’s friend profiles can access substantially more information.
It operates in two modes.
In online mode,
	inference is performed based on the friend’s profile where most frequently value is selected.
In offline mode,
	it uses only immediate friends and "network-only Bayes classifier" to measure the \textbf{probability of inference}.
The tool can suggest self sanitization actions based on the numerical value.

%1
%\cite{akcora_profiling_2014} focuses on on the risk of new interactions from a privacy point of view.

%2
\cite{b.s._privacy_2015} proposed a privacy control framework for information dispersal on social network,
	they use the quadratic form of bezier curve to arrive at privacy scores for friends,
	they use the \textbf{communication information} for pre-sorting of friends which is lacking in \cite{vidyalakshmi_privacy_2015}.

%3
\textbf{Privacy Index (PIDX)} proposed in \cite{nepali_sonet_2013} is a measure of a user’s privacy exposure in a social network.
PIDX is a numerical value between 0 and 100 with high value indicating high privacy risk in social networks.
An \textbf{attribute’s privacy impact factor} is a ratio of its privacy impact to full privacy disclosure.
Thus,
	an attribute’s privacy impact has a value between 0 and 1.
They consider privacy impact factor for full privacy disclosure is 1.

%4
%\cite{bilogrevic_multi-dimensional_2014} study the privacy of Social Relationships in Pervasive Networks.

%5
\cite{akcora_risks_2012} develop a graph-based approach and a risk model to learn \textbf{risk labels of strangers},
	the intuition of such an approach is that risky strangers are more likely to violate privacy constraints.

%Privacy Wizard
Fang and Le Fevre \cite{fang_privacy_2010} proposed a Privacy Wizard to help users grant privileges to their friends.
	the goal of this tool is to automatically configure a user’s privacy settings with minimal effort and interaction from the user.
The wizard asks users to first assign privacy \textbf{labels to selected friends},
	and then uses this as input to construct a classifier which classifies friends based on their profiles and automatically assign privacy labels to the unlabeled friends.

%Risk score
In a similar vein,
	some studies \cite{maximilien_privacyasaservice_2009} propose a methodology for quantifying the risk posed by a user’s privacy settings.
A risk score reveals to the user \textbf{how far his/her privacy settings are from those of other users}.
It provides feedback regarding the state of his/her existing settings.
However,
	it does not help the user refine his/her settings in order to achieve a more acceptable configuration.

Trust metrics can be classified to two main categories: global and local trust metrics.
%Local trust metrics
\textbf{Local trust metrics},
	compute trust values that are dependent on the target user,
	Local trust metrics take into account the very personal and subjective views of the users,
	they predict different values of trust for every single user based on their own experience.
%Global trust metrics
\textbf{Global trust metrics (reputation)},
	on the other hand,
	predict a global reputation value for each node.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Concept of trust}

In trust networks users can ask to rate other users,
	this means that,
	a user can express her level of trust in another user she has interacted with,
	i.e. express a trust statement such as "Alice, trust Bob as 0.8 in [0,1]".
The system can then aggregate all the trust statements in a single trust networks representing the relationships between users.
Trust metrics are algorithms whose goal is to predict,
	based on the trust network,
	the trustworthiness of "unknown" users,
	i.e. users in which a certain user didn’t express a trust statement.
Their aim is to reduce social complexity by suggesting how much an unknown user is trustworthy.
%E-Mail Prioritization using Online Social Network Profile Distance
Due to the increased use of OSNs,
	there is a growing number of studies that focus on using social network data for scoring messages in order to filter unwanted messages in messaging systems.
The difference between each study has to do with the way the concept of trust is represented,
	computed and used.

%Privacy and Social Capital in Online Social Networks
The concept of trust is used to indicate the relationship between two entities.
%Trust-involved access control in collaborative open social networks
Trust in an entity is a commitment to an action based on a belief that the future actions of that entity will lead to a good outcome.
There are three main properties of trust that are relevant to the development of algorithms for computing it \cite{wang_trustinvolved_2010},
	namely,
	transitivity,
	asymmetry,
	and personalization.
%transitivity
The primary property of trust that is used in our work is transitivity.
	if Alice highly trusts Bob,
	and Bob highly trusts Chuck,
	it does not always and exactly follow that Alice will highly trust Chuck.
%asymmetry
It is also important to note the asymmetry of trust,
	for two people involved in a relationship,
	trust is not necessarily identical in both directions.
%personalization
The third property of trust that is important in social networks is the personalization of trust,
	trust is inherently a personal opinion,
	two people often have very different opinions about the trustworthiness of the same person.

%10
%Protect_U & Privacy Wizard
While much work has focused on tools for understanding and adjusting existing privacy settings,
	\textbf{Protect\_U} \cite{gandouz_protect_2012} uses machine learning techniques to recommend privacy settings based on a user’s personal data and trustworthy friends.
Protect\_U analyzes user profile contents and ranks them according to four risk levels: Low Risk, Medium Risk, Risky and Critical.
The system then suggests personalized recommendations to allow users to make their accounts safer.
In order to achieve this,
	it draws upon two protection models: local and community-based.
The first model uses the \textbf{user’s personal data} in order to suggest recommendations,
The second model seeks the \textbf{user’s trustworthy friends} to encourage them to help improve the safety of their counter part’s account.

%Social Market
Despite the mole of work on social trust,
	Social Market is the first system to propose the use of \textbf{trust relationships} to build a decentralized interest-based marketplace.

%9 TAPE
Similarly,
	TAPE \cite{yongbozeng_study_2015} is the first attempt to combine explicit and implicit social networks into a single gossip protocol.
Zeng et al. \cite{yongbozeng_study_2015} approaches the privacy quantification problem from a different angle.
First,
	they consider \textbf{how likely a friend reveals others’ personal information},
	by computing the privacy trust score,
	which is a widely studied research problem \cite{gundecha_exploiting_2011}.
Furthermore,
	the proposed work is related to \textbf{information diffusion in OSNs} such as \cite{fang_privacy_2010}.
Finally,
TAPE framework differs from other work,
	in considering information diffusion in the context of privacy protection,
	which requires different sets of features and considerations.

%9
%Zeng and Xing \cite{yongbo_zeng_study_2015}
%	studied how individual users can expand their social networks by making trustful friends who will not leak their private IFs to unknown parties.

%Ostra
\textbf{Ostra} \cite{mislove_ostra_2008} utilizes trust relationship to thwart unwanted communication,
	where the number of a user’s trust relationships is used to limit the amount of unwanted communications he can produce.
Ostra utilizes the existing trust relationship among users to charge the senders of unwanted messages and thus block spam.
It relies on existing trust networks to connect senders and receivers via \textbf{chains of pair-wise trust relationship},
	they use a pair-wise link-based credit scheme to impose a cost on originator of unwanted communication.
Unfortunatly,
	the scalability of this system stays uncertain as it employs a per-link credit scheme.

%8
Gundecha et al. \cite{gundecha_exploiting_2011} propose a feasible approach to the problem of identifying a user’s vulnerable friends on a social networking site.
Vulnerability is somewhat contagious in this context.
Their work differs from existing work addressing social networking privacy by introducing a \textbf{vulnerability-centered approach to a user} security on a social networking site.
On most social networking sites,
	privacy related efforts have been concentrated on protecting individual attributes only.
However,
	users are often vulnerable through community attributes.
Unfriending vulnerable friends can help protect users against the security risks.

%
In \cite{zeng_trustaware_2014},
	Sun et al proposed a \textbf{probability trust model} that uses Beta function to address concatenation propagation and multi-path propagation of trust.

%LENS: Leveraging Social Networking and Trust to Prevent Spam Transmission

%SOAP
\textbf{SOAP} \cite{li_soap_2011} presents a social network based personalized spam filter that integrates \textbf{social closeness},
	\textbf{user (dis)interest} and adaptive \textbf{trust} management into a Bayesian filter.
SOAP proposed an email scoring mechanism based on an email network augmented with reputation ratings.
An email is considered spam if the \textbf{reputation score of the email sender} is very low.
Different from these social network based methods,
	SOAP focuses on personal interests in conjunction with social relationship closeness for spam detection.
However,
	several issues with SOAP,
	including the intrinsic cost of initialization and continuous adaptation of social closeness (between sender and recipient),
	and social interests (of an individual) in the Bayesian filter,
	limit its usage.

%6
Relationship between \textbf{user’s trustworthiness} and privacy risk is presented in \cite{pandey_computing_2015}.

%LENS
Hameed \cite{hameed_lens_2011} proposed LENS,
	which extends the FoF network by adding trusted users from outside of the FoF networks to mitigate spam beyond social circles.
Only emails to a recipient that have been \textbf{vouched by the trusted nodes} can be sent into the network.
The authors proposed using social networks and trust and reputation systems to combat spam.
In contrast,
	LENS can reject unwanted email traffic during the SMTP time.

%SocialEmail
SocialEmail \cite{tran_social_2010} considers the trust as an integral part of networking rather than working alongside of an existing communication system.
SocialEmail leverages \textbf{social network trust paths} to rate the messages.
The key feature of SocialEmail is that instead of directly connecting the sender and the recipient,
	messages are routed through existing friendship links.
This gives each email recipient control over who can message him/her,
In contrast,
	such social interaction-based methods are not sufficiently effective in dealing with legitimate emails from senders outside of the social network of the receiver.

%Social interactions
Social interactions (e.g.,
	\textbf{the exchange of messages between users}) have been suggested as an indicator of interpersonal tie strength \cite{xiang_modeling_2010}.
As a consequence,
	an unsupervised model has been developed to estimate the \textbf{relationship strength} from the interaction activity and the user similarity in the OSN \cite{xiang_modeling_2010}.
Although interaction-based methods leverage \textbf{social relationships} for extracting trust,
	the applications are not designed to be automated in the sense that the user must explicitly score other users,
	score messages,
	create whitelists or adjust the credits.
%Furthermore,
%	none of the aforementioned trust models are utilized to prioritize the E-mail senders.

%access control model
Fong \cite{fong_relationshipbased_2011} formulated this paradigm called a Relationship-Based Access Control (ReBAC) model,
	it bases authorization decisions on the \textbf{relationships between the resource owner and the resource accessor} in an OSN.
However,
	most of these existing work could not model and analyze access control requirements with respect to collaborative authorization management of shared data in OSNs.

%\paragraph{Trust networks and trust metrics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Concept of reputation}

Trust and reputation concepts are used in order to preserve user’s privacy while increasing their social capital in OSNs.
%Privacy and Social Capital in Online Social Networks
Reputation concept is used to refer to a more general sense of trust towards a particular entity based on opinions of multiple entities.

%Social network analysis for cluster-based IP spam reputation
%Reputation-based systems.
A reputation system collects,
	distributes and aggregates feedback about participants’ past behavior.
Such systems help people decide whom to trust,
	encourage trustworthy behavior and deter participation by those who are unskilled or dishonest.
%Real-time reputation-based systems.
Various applications use real-time reputation-based systems,
	including online markets and anti-spam solutions.
Anti-spam reputation systems generate a score,
	or rating,
	for each incoming message or IP,
	based on analysis of various parameters: message volume,
	type of traffic (e.g. sporadic vs continuous),
	rate of user complaint reports,
	feedback from spam traps,
	compliance with regulations,
	etc.
This aggregated information,
	collected over time,
	forms the reputation of the sender.

%SNARE
SNARE \cite{hao_detecting_2009} infers the reputation of a message sender based on \textbf{network-level features},
	(e.g. \textbf{geodesic distance between sender and recipient, number of recipients}).
The most influential feature in the system was the AS number of the sender.
Using an automated reputation engine,
	SNARE classifies message senders as spammers or legitimate with about a 70\% detection rate for less than a 0.3\% false positive rate,
	without looking at the contents of a message.
However,
	lacking authentication and non-repudiation in standard trust and reputation solution make these solutions be subject to identity spoofing,
	false accusation and collusion attacks.
Further,
	these solutions consume extra valuable resources of messaging servers on message reception and filtering.

%TrustMail
In TrustMail,
	which is a prototype E-mail client,
	an approach is proposed that makes use of OSN reputation ratings to attribute different scores to E-mails \cite{golbeck_reputation_2004}.
The actual benefit of this system is that,
	by using \textbf{social network data},
	it identifies potentially important and relevant messages even if the recipient does not know the sender \cite{golbeck_reputation_2004}.

%Cluster-based reputation
Qian et al. \cite{qian_networklevel_2010} addressed this issue by presenting a clustering technique that refines \textbf{AS-based and BGP prefix-based clusters}.
The authors combined \textbf{BGP and DNS information} to identify a cluster of IP addresses within the same administrative boundary,
	and thus constructed the reputation for an entire cluster.
This cluster-based reputation system allowed more accurate identification of the reputation of previously unknown IP addresses,
	and reduced the false negative rate by 50 percent compared to blacklists,
	without increasing the false-positive rate \cite{qian_networklevel_2010}.

%2 multi-agent based reputation model
Paradesi et al. \cite{paradesi_integrating_2009} adopted a multi-agent based reputation model to define \textbf{trustworthiness of services}.
Moreover,
	they developed a trust framework to derive trust for a composite service from trust model of component services.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Collaborative management}

%Trust-involved access control in collaborative open social networks
%collaborative community

The trust value assigned to a person in previous work is estimated on the basis of his/her reputation,
	which can be assessed taking into account the person behaviour.
Indeed,
	it is a matter of fact that people assign to a person with unfair behaviour a bad reputation and,
	as a consequence,
	a low level of trust.
A possible solution is to estimate the trust level to be assigned to a user in a collaborative community on the basis of his/her reputation,
	given by his/her behavior with regards to all the other users in the community.

%Detecting and Resolving Privacy Conflicts for collaborative Data Sharing in Online Social Networks
Hu et al. \cite{hu_detecting_2011} propose an approach to enable \textbf{collaborative privacy management} of shared data in OSNs.
In particular,
	they provide a systematic mechanism to identify and resolve privacy conflicts for collaborative data sharing.
their conflict resolution indicates a trade-off between privacy protection and data sharing by quantifying privacy risk and sharing loss

%Interdependent Privacy: Let Me Share Your Data
%collaborative
Dealing with \textbf{collaborative information sharing},
	Hu et al. \cite{biczok_interdependent_2013} proposed a method to detect and resolve privacy conflicts.

%COAT : Collaborative Outgoing Anti-Spam Technique
%community collaboration
The collaborative systems, called \textbf{COAT} \cite{ahmad_coat_2012}, do not rely upon semantic analysis but on the community to identify spam messages.
Once a message is tagged as spam by one SMTP server,
	the signature of that message is transmitted to all other SMTP servers.
This class requires the collaboration of multiple SMTP servers to implement the system.

%SocialFilter
\textbf{SocialFilter} \cite{yang_socialfilter_2009} proposes a collaborative spam mitigation system that uses social trust embedded in OSN to asses the trustworthiness of Spam reporter.
The spammer reports from the SocialFilter nodes are stored at a centralized repository that computes the trust values of the reports and identifies spammers based on IP addresses.
However,
	the SocialFilter’s effectiveness is doubtful as spammers may use dynamic IPs.

%collective privacy management
Squicciarini et al. \cite{hu_detecting_2011} proposed a solution for collective privacy management for photo sharing in OSNs.
This work considered the privacy control of a content that is co-owned by multiple users in an OSN,
	such that each co-owner may separately specify her/his own privacy preference for the shared content.
The Clarke-Tax mechanism was adopted to enable the collective enforcement for shared content.
Game theory was applied to evaluate the scheme.
However,
	a general drawback of this solution is the usability issue,
	as it could be very hard for ordinary OSN users to comprehend the Clarke-Tax mechanism and specify appropriate bid values for auctions.
In addition,
	the auction process adopted in their approach indicates only the winning bids could determine who was able to access the data,
	instead of accommodating all stakeholders’ privacy preferences.








