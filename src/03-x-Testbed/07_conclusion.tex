\section{Discussion} \label{sec:Conclusion}

%purpose
The purpose of the project was to find and examine a communication protocol that could be suitable for IoT applications,
	by investigating the current hardware,
	OS,
	and communication protocols and building a prototype from the selected choices.
What can be said about the investigation is that it is difficult to examine all candidates in detail;
	this means that a rough selection has to be made based on initial knowledge potentially discarding good options.
The general feeling is,
	however,
	that all of the examined candidates in this project were relevant and added valuable insights to the current technology status.
The assessment gave relevant and interesting results that improved the understanding in what IoT can be used for,
	and what further areas of investigation could be.
One of the most interesting areas of further investigation would be the RDC driver,
	as it directly affects the response time and thus also the connection speed.
Even though the power consumption was not in line with the expectations,
	the reason has been found and can be resolved.
Another conclusion is that IoT is not ready for real-time applications as the latency is much higher than expected,
	for the technologies assessed in this thesis,
	and also has a high spread.
As the latency increases for each subsequent network hop and the minimum observed latency per hop is 11ms,
	when using the always-on RDC,
	this type of communication will probably only be used for applications where response time can vary greatly,
	without affecting the functionality.
CoAP as a communication protocol shows a lot of promise when combined with 6LoWPAN and IEEE 802.15.4.
It performs well given its simplicity but has one disadvantage:
	the large overhead which comes from the MAC addressing fields in the IEEE 802.15.4 frame.
If this overhead could be reduced from the current 71\% to only 30%,
	the goodput would double.
A solution would be to use a similar mechanism as BLE where the packet size varies depending on application.
Each node also has computing time left as the MCU is more powerful  than needed for the given application;
	an improvement would be to use a less powerful MCU,
	like the ARM Cortex-M0+,
	to reduce the clock speed as suggested in the discussion.
When looking at the future-proof aspect the later suggestion is probably the better,
	as the clock then could be increased if more computing power is needed.
In the future,
	batteries will hopefully be able to store more energy,
	thus increasing the time between battery changes or reducing the battery size.

