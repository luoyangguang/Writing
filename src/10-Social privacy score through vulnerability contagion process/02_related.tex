\section{Related work}

% You have to express the need with urgenssy feeling                                           Context
% You have to express the bad (limitation) of exesting sollution in satisfying such need       Problematic
% You have to express the good things that can be made if we satisfy this needs                Motivation
% You have to express the level of deffficulty                                                 Challenges
% You have to express the the list of contribution                                             List od Contribution
% You have to express the structure of your work                                               Structure

% First contribution
% You have to express the current sollutions                                                   Related work
% You have to express the limitation and the advantage that can be reused                      Limitations
% You have to express the advantage that can be reused                                         Background

% You have to express you approach                                                             Approach
% You have to express the validity of your approach                                            Experimentation
% You have to express the resultes that express                                                Results interpretaion

% Second contribution
% You have to express the current sollutions                                                   Related work
% You have to express the limitation and the advantage that can be reused                      Limitations
% You have to express the advantage that can be reused                                         Background

% You have to express you approach                                                             Approach
% You have to express the validity of your approach                                            Experimentation
% You have to express the resultes that express                                                Results interpretaion

% Third contribution
% You have to express the current sollutions                                                   Related work
% You have to express the limitation and the advantage that can be reused                      Limitations
% You have to express the advantage that can be reused                                         Background

% You have to express you approach                                                             Approach
% You have to express the validity of your approach                                            Experimentation
% You have to express the resultes that express                                                Results interpretaion

% You have to express the big challenges                                                      Challenges
% You have to express the contribution                                                        Contribution
% You have to express the results                                                             Results
% You have to express the assumption made to get such results                                 Limitations
% You have to express the future work                                                         Background

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Research categories %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To evaluate the privacy risk of social network users,
	trust metrics are used to measure the extent to which users can be trusted.
Trust metrics can be classified into two main categories:
	global and local trust metrics.

%Local trust metrics 
Local trust metrics,
	compute trust values that are dependent on the target user,
	they take into account the very personal and subjective views of the users,
	they predict different values of trust for every single user based on their own experience.
%Global trust metrics 
Global trust metrics,
	on the other hand,
	predict a global reputation value for each node,
	based rather on the experience of all other users or on the topology of the social network.

%\subsection{Local Trust-based methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Discuss important findings and find some relevance for them %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Protect_U & Privacy Wizard
While much work has focused on tools for understanding and adjusting existing privacy settings,
	Protect\_U \cite{gandouz_protect_2012} uses machine learning techniques to recommend privacy settings based on a user’s personal data and trustworthy friends.
Protect\_U analyzes user profile contents and ranks them according to four risk levels: Low Risk, Medium Risk, Risky and Critical.
The system then suggests personalized recommendations to allow users making their accounts safer.
In order to achieve this,
	it draws upon two protection models: local and community-based.
The first model uses the user’s personal data in order to suggest recommendations,
The second model seeks the user’s trustworthy friends to encourage them to help improve the safety of their counter part’s account.

%Social Market
Despite the mole of work on social trust,
	Social Market \cite{frey_social_2011} is the first system to propose the use of trust relationships to build a decentralized interest-based marketplace.
%9 TAPE
Similarly,
	TAPE \cite{yongbozeng_study_2015} is the first attempt to combine explicit and implicit social networks into a single gossip protocol.
Zeng et al. \cite{yongbozeng_study_2015} approaches the privacy quantification problem from a different angle.
First,
	they consider how likely a friend reveals others’ personal information,
	by computing the privacy trust score,
	which is a widely studied research problem \cite{gundecha_exploiting_2011}.
Furthermore,
	the proposed work is related to information diffusion in OSNs such as \cite{fang_privacy_2010}.
TAPE framework differs from other work,
	in considering information diffusion in the context of privacy protection,
	which requires different sets of features and considerations.

%9
Zeng and Xing \cite{zeng_trustaware_2014}
	studied how individual users can expand their social networks by making trustful friends who will not leak their private information to unknown parties.
This work proposes a security risk estimation framework of social networking privacy to calculate the probability of individual privacy leakage through the social graph.
The framework is composed of two parts,
	the calculation of Individual Privacy Leakage Probability (IPLP) and the Relationship Privacy Leakage Probability (RPLP).
Relationship Privacy Leakage Probability considers the factors of relationship strength and interactive behaviors.
Two vectors namely privacy protection awareness (PPA) and privacy protection trust (PPT) are proposed in this paper to estimate IPLP.

%IPLP is regarded as the probability user would gossip others’ privacy in his/her moments,
%	 while the user has heard and been attracted by others’ personal information,

%Ostra
Ostra \cite{mislove_ostra_2008} utilizes trust relationship to thwart unwanted communication,
	where the number of a user’s trust relationships is used to limit the number of unwanted communications he can produce.
Ostra utilizes the existing trust relationship among users to charge the senders of unwanted messages and thus block spam.
It relies on existing trust networks to connect senders and receivers via chains of a pair-wise trust relationship,
	they use a pair-wise link-based credit scheme to impose a cost on the originator of the unwanted communication.
Unfortunately,
	the scalability of this system stays uncertain as it employs a per-link credit scheme.

%8
Gundecha et al. \cite{gundecha_exploiting_2011} propose a feasible approach to the problem of identifying a user’s vulnerable friends on a social networking site.
Vulnerability is somewhat contagious in this context.
Their work differs from existing work addressing social networking privacy by introducing a vulnerability-centered approach to a user security on a social networking site.
On most social networking sites,
	privacy-related efforts have been concentrated on protecting individual attributes only.
However,
	users are often vulnerable through community attributes.
Unfriending vulnerable friends can help protect users against the security risks.

%In \cite{sun_trust_2006},
%	Sun et al proposed a probability trust model that uses the Beta function to address concatenation propagation and multi-path propagation of trust.

%SOAP
%SOAP \cite{li_soap_2011} presents a social network based personalized spam filter that integrates social closeness,
%	user (dis)interest and adaptive trust management into a Bayesian filter.
%SOAP proposed an email scoring mechanism based on an email network augmented with reputation ratings.
%An email is considered spam if the reputation score of the email sender is very low.
%Different from these social network based methods,
%	SOAP focuses on personal interests in conjunction with social relationship closeness for spam detection.
%However,
%	several issues with SOAP,
%	including the intrinsic cost of initialization and continuous adaptation of social closeness (between sender and recipient),
%	and social interests (of an individual) in the Bayesian filter,
%	limit its usage.

%LENS: Leveraging Social Networking and Trust to Prevent Spam Transmission
Hameed \cite{hameed_lens_2011} proposed LENS,
	which extends the friend of friend network by adding trusted users from outside of the FoF networks to mitigate spam beyond social circles.
Only emails to a recipient that have been vouched by the trusted nodes can be sent into the network.
The authors proposed using social networks and trust and reputation systems to combat spam.
In contrast,
	LENS can reject unwanted email traffic during the SMTP time.

%SocialEmail
SocialEmail \cite{tran_social_2010} considers trust as an integral part of networking rather than working alongside an existing communication system.
SocialEmail leverages social network trust paths to rate the messages.
The key feature of SocialEmail is that instead of directly connecting the sender and the recipient,
	messages are routed through existing friendship links.
This gives each email recipient control over who can message him/her,
In contrast,
	such social interaction-based methods are not sufficiently effective in dealing with legitimate emails from senders outside of the social network of the receiver.

%Social interactions
Social interactions (e.g.,
	the exchange of messages between users) have been suggested as an indicator of interpersonal tie strength \cite{xiang_modeling_2010}.
As a consequence,
	an unsupervised model has been developed to estimate the 
		relationship strength from the interaction activity and the user similarity in the OSN \cite{xiang_modeling_2010}.
Although interaction-based methods leverage social relationships for extracting trust,
	the applications are not designed to be automated in the sense that the user must explicitly score other users,
	score messages,
	create whitelists or adjust the credits.

%%Access control model
%Fong et al. \cite{fong_relationshipbased_2011} formulated this paradigm called a Relationship-Based Access Control (ReBAC) model,
%	it bases authorization decisions on the relationships between the resource owner and the resource accessor in an OSN.
%However,
%	most of these existing work could not model and analyze access control requirements with respect to collaborative authorization management of shared data in OSNs.

%\cite{wisniewski_profiling_2014} focuses on the risk of new interactions from a privacy point of view.

Vidyalakshmi et al. \cite{b.s._privacy_2015} proposed a privacy control framework for information dispersal on social network,
	they use the quadratic form of bezier curve to arrive at privacy scores for friends,
	they use the communication information for pre-sorting of friends which is lacking in \cite{vidyalakshmi_privacy_2015}.
Similarly,
Akcora et al. \cite{akcora_risks_2012} develop a graph-based approach and a risk model to learn risk labels of strangers,
	the intuition of such an approach is that risky strangers are more likely to violate privacy constraints.

Privacy Index (PIDX) proposed in \cite{nepali_sonet_2013} is a measure of a user’s privacy exposure in a social network.
PIDX is a numerical value between 0 and 100 with a high value indicating high privacy risk in social networks.
An attribute’s privacy impact factor is a ratio of its privacy impact to full privacy disclosure.
Thus,
	an attribute’s privacy impact has a value between 0 and 1.
They consider the privacy impact factor for full privacy disclosure is 1.

%Privacy Wizard
Fang and Le Fevre \cite{fang_privacy_2010} proposed a Privacy Wizard to help users grant privileges to their friends.
	the goal of this tool is to automatically configure a user’s privacy settings with minimal effort and interaction from the user.
The wizard asks users to first assign privacy labels to selected friends,
	and then uses this as input to construct a classifier which classifies friends based on their profiles and automatically assign privacy labels to the unlabeled friends.
%Risk score
In a similar way,
	some studies \cite{maximilien_privacyasaservice_2009} propose a methodology for quantifying the risk posed by a user’s privacy settings.
A risk score reveals to the user how far her privacy settings are from those of other users.
It provides feedback regarding the state of her existing settings.
However,
	it does not help the user refine her settings in order to achieve a more acceptable configuration.

%		Yu and Singh The TRS model proposed by Yu and Singh [113] uses two information sources.
%		The first one contains the entity’s belief built as a result of its direct interaction with other entities.
%		The second one includes the testimonies of third-parties that can be beneficial in the absence of local ratings.
%		The model proposes a trust network which tries to locate the most appropriate witnesses in a multi-agent system.
%		When a requesting entity wants to evaluate the trustworthiness of other entity,
%			it sends a query to the neighbors of that entity asking for their perception regarding the target entity.
%		This model deals with malicious entities who deliberately disseminate misinformation through the network.

%		REGRET REGRET [114] is a decentralized TRS designed for complex e-commerce environments 
%			where various types of entities with different social relationships play important roles.
%		It describes the social structure and relationships of the system through the ideas of cooperation,
%			competition,
%			and trade.
%		REGRET is based on a three-dimensional reputation model: 
%			Individual dimension or subjective reputation which calculates trust based on the direct impressions of an entity; social dimension,
%			which is divided into three types of reputation:
%			witness reputation,
%			neighborhood reputation,
%			and system reputation; and ontological dimension,
%			which adds the possibility of combining different aspects of reputation to calculate a complex one.
%		With the help of the ontological structure,
%			each entity is capable of determining the overall reputation of a particular entity 
%				by assigning the appropriate influence degree to each aspect related to its demand.
%		In addition to the reputation value,
%			REGRET gives a reliability measurement which reflects the confidence level of the produced reputation value.

%		2.3.10
%		Aberer and Despotovic The model proposed by Aberer and Despotovic [115] is one of the first TMS focused on P2P networks.
%		It is based on the complaints a peer receives from other peers in the network.
%		Although it improves network performance in stable environments,
%			due to the naive of its approach,
%			it is highly sensitive to malicious peers.
%		However,
%			it served as a baseline to subsequent models in this area of application.

%		2.3.11
%		Esfandiary and Chandrasekharan The model proposed by Esfandiary and Chandrasekharan [116] uses to sources of information:
%			observation and interaction.
%		The processing of observed information is based on Bayesian learning.
%		The interaction is based on two main protocols:
%			an exploratory protocol and a query protocol.
%		In the exploratory protocol,
%			entities ask the other entities about known topics to evaluate their degree of trust.
%		Answers consistent with their knowledge yield to consider an entity as trusted.
%		In the query protocol,
%			entities ask for advice to previously trusted entities.
%		The authors claim that the calculation of this trust interval is equivalent to the problem of routing in a communication network and,
%			therefore,
%			known distributed algorithms used to solve that problem can be successfully applied to this situation.
%			
%		%grouping friends
%		Jones et al. (Jones and O’Neill, 2010) investigate users’ rationales for grouping friends,
%			for privacy management purposes,
%			within online social networks.
%		They identify six static criteria for grouping,
%			and evaluate the similarity of these criteria to the output of standard clustering techniques of users’ friends.
%		Their work supports our notion that standard clustering techniques can assist users in placing friends into groups analogous with privacy intentions.

%		%inference of private data from public one
%		In general,
%			semi-supervised learning has been used in social networks to infer users’ private information from the public labeled and unlabeled data 
%				using graph-based semi-supervised learning,
%			e.g. (Javed and Shehab, 2012).

%		%Legitimacy scores
%		Lam et al. [32] proposed a learning approach for spam sender detection based on user interaction features (e.g.,
%			indegree/outdegree and interaction frequency) extracted from social networks constructed from email exchange logs.
%		Legitimacy scores are assigned to senders based on their likelihood of being a legitimate sender.

%		%Four security metrics
%		Lippmann et al. [23] have introduced meaningful security metrics that motivate effective improvements in network security.
%		They present a methodology for directly deriving security metrics from realistic mathematical models of adversarial behaviors.
%		Four security metrics are described that assess the risk from prevalent network threats.
%		These initial four metrics and additional ones should be added incrementally to a network to gradually improve overall security as scores drop.

%		The social trust is divided into explicit social trust and implicit social trust[13].

%		The trust value assigned to a person in previous work is estimated on the basis of his/her reputation,
%			which can be assessed taking into account personal behavior.
%		Indeed,
%			it is a matter of fact that people assign to a person with unfair behavior a bad reputation and,
%			as a consequence,
%			a low level of trust.
%		A possible solution is to estimate the trust level to be assigned to a user in a collaborative community on the basis of his/her reputation,
%			given by his/her behavior with regards to all the other users in the community.

%		%SocialFilter
%		\textbf{SocialFilter} \cite{yang_socialfilter_2009} proposes a collaborative spam mitigation system 
%			that uses social trust embedded in OSN to asses the trustworthiness of Spam reporter.
%		The spammer reports from the SocialFilter nodes are stored at a centralized repository that computes the trust values of the reports and identifies spammers based on IP addresses.
%		However,
%			the SocialFilter’s effectiveness is doubtful as spammers may use dynamic IPs.

%		comes from the social network topology,
%			such as the graph similarity between peers,
%			the number of friends,
%			and \textbf{betweenness centrality},
%			etc.[14] For example,
%			a peer who has many friends can be estimated to have more benevolence and integrity than other peers.
%		Moreover,
%			peers trust their friends[15],
%			that is,
%			peers estimate the integrity of their friends higher than others.
%			
%		%social
%		DeBarr et al. [31] evaluated the use of social network analysis measures to improve the performance of a content filtering model.
%		They tried to detect spam by measuring the degree centrality of message relay agents and the average path length between senders and receivers.
%		They claimed that the messages from a promiscuous mail relay or messages with unusual path lengths that deviate from the average are more likely to be spam.

%		%clustering coefficient
%		Boykin et al. [3],[25] constructed a graph in which vertices represent email addresses and direct edges represent email interactions.
%		Emails are identified as spam,
%			valid,
%			or unknown based on the local clustering coefficient of the graph subcomponent.
%		This is based on the rationale that the social communication network of a normal node has a higher clustering coefficient than that of a spam node.

%		%social network analysis metrics
%		Herein,
%			we suggest that the accuracy of cluster-based systems can be improved by using social network analysis metrics.
%		Using one or more of these parameters may provide an amplified view of the AS by increasing granularity,
%			i.e. the sub-division of cluster information.

%		In [35],
%			authors introduce a new metric,
%			namely topological anonymity,
%			to quantify the level of anonymity using the topology properties of the network graph. [44] introduces neighborhood attacks,
%			in which an adversary knows the neighborhood subgraph of the target,
%			and tries to reidentify the user from an anonymized network graph.
%		They propose an approach to further anonymize vertexes by modifying edges to construct isomorphic neighborhoods.

%		In [28],
%			authors define k-degree anonymity:
%			in a k-degree anonymized graph,
%			each node has the same degree with at least k other nodes.
%		They also efficiently propose k -degree anonymize graphs with minimal edge additions and deletions.

%		Moreover,
%			[15] models three types of adversary knowledge that could be used to re-identify vertexes from an anonymized social network graph.
%		They tackle the problem through graph generalization – dividing the graph into partitions and publishing summarized partition-level data.
%		K-Automorphism is introduced in [46] to defend against multiple attacks.

%		In [18],
%			authors propose a graph anonymization approach that maximally preserves original graph structure and statistical features.

%		Finally,
%			[31] considers social network as a weighted graph,
%			in which edge labels are also considered to be sensitive.
%		They propose to protect sensitive edge labels while keeping certain global features of the graph.

%		Our proposed method is the first that leverages social distance and interest relationship from a social network to identify suspicious collusion 
%			and to reduce its influence on node reputation.

%		%infer private user information
%		Researchers [18, 19] demonstrated the ability to infer private user information using only friendship links,
%			group memberships and information shared by others publicly.
%			
%		%Inference problems
%		Previous studies of user privacy have focused on sensitive attribute inference problems,
%			where user private attributes are detected based on a mix of public profiles in the network,
%			friendship links and group membership information of private users [47].
%		Specifically,
%			within the friendship identification and inference attack [23],
%			a user might aim to infer private attributes of another user.

%		%Link prediction problem
%		The link prediction problem has also been applied to predict links between non-users of Facebook [20],
%			given only the link information towards non-members from the known network.
%		Additionally,
%			the network completion problem aims to infer both missing links and nodes,
%			where it has been shown that the missing part of the network can be inferred based only on the connectivity patterns of the observed part [5].

%						risk labeling approach
%		In \cite{raad_privacy_2013},
%			the authors use risk labeling approach to tag users based on the community members’ feedback.
%		Active learning method is used to correctly label strangers.

%		is measured by checking the communication history.
%		Peers,
%			who do not connect to each other in an online social network,
%			also can generate the social relationship.
%		If they interact with each other through messengers or e-mail,
%			then they have implicit social trust.
%		The frequency and the duration of the communication affect to the implicit social trust.

Abdul-Rahman and Hailes The trust model presented by Abdul-Rahman and Hailes \cite{abdul-rahman_supporting_2000} 
	is focused on virtual communities related to e-commerce and artificial autonomous agents.
The model defines direct trust and recommender trust.
Direct trust is the trust of an entity in another one based on direct experience.
Whereas recommender trust is the trust of an entity in the ability to provide good recommendations.
Trust can only have discrete labeled values,
	namely Very Trustworthy,
	Trustworthy,
	Untrustworthy,
	and,
	Very Untrustworthy for direct trust,
	and Very good,
	good,
	bad and,
	very bad for recommender trust.
The difference between the two ratings from different entities can be computed as semantic distance.
This semantic distance can be used to adjust further recommendations.
The combination of ratings is done as a weighted sum,
	where the weights depend on the recommender trust.

%\subsection{Global Trust-based methods}

%%SNARE
%SNARE \cite{hao_detecting_2009} infers the reputation of a message sender based on network-level features,
%	(e.g. geodesic distance between sender and recipient, number of recipients).
%The most influential feature in the system was the AS number of the sender.
%Using an automated reputation engine,
%	SNARE classifies message senders as spammers or legitimate with about a 70\% detection rate for less than a 0.3\% false positive rate,
%	without looking at the contents of a message.
%However,
%	lacking authentication and non-repudiation in standard trust and reputation solution make these solutions be subject to identity spoofing,
%	false accusation and collusion attacks.
%Further,
%	these solutions consume extra valuable resources of messaging servers on message reception and filtering.

%%TrustMail
%In TrustMail,
%	which is a prototype E-mail client,
%	an approach is proposed that makes use of OSN reputation ratings to attribute different scores to E-mails \cite{golbeck_reputation_2004}.
%The actual benefit of this system is that,
%	by using social network data,
%	it identifies potentially important and relevant messages even if the recipient does not know the sender \cite{golbeck_reputation_2004}.

%%Cluster-based reputation
%Qian et al. \cite{qian_networklevel_2010} addressed this issue by presenting a clustering technique that refines AS-based and BGP prefix-based clusters.
%The authors combined BGP and DNS information to identify a cluster of IP addresses within the same administrative boundary,
%	and thus constructed the reputation for an entire cluster.
%This cluster-based reputation system allowed more accurate identification of the reputation of previously unknown IP addresses,
%	and reduced the false negative rate by 50 percent compared to blacklists,
%	without increasing the false-positive rate \cite{qian_networklevel_2010}.

%%2 multi-agent based reputation model
%Paradesi et al. \cite{paradesi_integrating_2009} adopted a multi-agent based reputation model to define trustworthiness of services.
%Moreover,
%	they developed a trust framework to derive trust for a composite service from the trust model of component services.
%Relationship between user’s trustworthiness and privacy risk is presented in \cite{pandey_computing_2015}.

%		%Trust-ware: A Methodology to Analyze, Design, and Secure Trust and Reputation Systems
%		Policy-based vs. reputation-based: there are two main approaches to evaluate trust in the literature,
%			namely: policy-based trust management and reputation-based trust management [100]–[103].

%		evaluate the peer’s trust using a system which aggregates the feedback of peers about their opponent’s integrity,benevolence, and ability[9].

%		2.1) \textbf{Feedback based reputation} evaluation is the most popular method to assess the trustworthiness of peers in e-commerce services.
%		Paul et al.[10] studied the trust among peers in Ebay[11],
%			which is one of the famous e-commerce services.
%		They investigate the ability of a peer (e.g. the discount rate,
%			fast shipping) and the integrity of a peer (e.g. the quality of a product,
%			etc.) Mehmet et al.[12] studied the patterns of participation and exchange in Airbnb.
%		In detail,
%			they investigated how income,
%			race,
%			and education affect the economic activity on Airbnb and found that education is a heavily influential factor.

%		Sporas In this model [110],
%			only the most recent rating between two entities is considered.
%		Besides,
%			entities with very high reputation values experience much smaller reputation changes after each update than entities with a low reputation.
%		Sporas incorporates a measure of the reliability of the entities’ reputation based on the standard deviation of reputation values.
%		It is robust to changes in the behavior of an entity and the reliability measure improves the usability of the reputation value.

%		Histos Histos [110] was designed as a response to the lack of personalization that Sporas reputation values have.
%		The model can deal with direct information and witness information.
%		In this case,
%			the reputation value is a subjective property assigned particularly by each individual (actually becoming a trust value).
%		The treatment of direct interaction in this reputation model is limited to the use of the most recent experience with the agent that is being evaluated.
%		The strength of the model relies on its use of witness information.
%		Ratings are represented as a directed graph.
%		The reputation of an agent at level n of the graph (with n > 0) is calculated recursively 
%			as a weighted mean of the rating values that entities in level X − 1 gave to that entity.
%		A drawback of this model is the use of the reputation value assigned to a witness also as a measure of its reliability.

%		Schillo et al.
%		This trust model [112] is oriented to scenarios where the result of an interaction between two entities is good or bad.
%		This value is a subjective property assigned particularly by each individual and it does not depend on the context.
%		It is based on a Prisoner’s dilemma set of games [42] with a partner selection phase.
%		Each agent receives the results of the game it has played plus the information about the games played by a subset of all players (its neighbors).
%		The model is based on probability theory that uses the number of times that the target entity was honest.
%		Besides,
%			an entity can get information from other agents that it has met before.
%		The answer of witnesses to a query is the set of observed experiences,
%			and not a summary of them.
%		The model assumes that witnesses never lie but that can hide (positive) information in order to make other agents appear less trustworthy.

%		2.3.12
%		Afras The main characteristic of this model [117] is the use of fuzzy sets to represent reputation values.
%		Once a new fuzzy set that shows the degree of satisfaction of the latest interaction with a given entity is calculated,
%			the old reputation value and the new satisfaction value are aggregated using a weighted aggregation.
%		Besides,
%			the weights of this aggregation are calculated from a single value that they call remembrance or memory.
%		Recommendations from other entities are aggregated directly with direct experiences.
%		If they come from a recommender with a high reputation,
%			they have the same degree of reliability as a direct experience.

%		2.3.13
%		Azzedin and Maheswaran Azzedin and Maheswaran [118] propose a TMS based on a combination 
%			of direct trust and reputation by weighting the two components differently.
%		It gives more weight to direct trust.
%		This direct trust o trust level is calculated based on past experiences and is given for a specific context.
%		Calculation of reputation values is based on a neural network approach.

%		2.3.14
%		Carter et al.
%		Carter et al. propose a complex but novel TMS [119] based on the concept of roles.
%		They claim that the reputation of an agent is based on the degree of fulfillment of roles ascribed to it by the society.
%		Therefore,
%			if society judges that an entity has met its roles,
%			it will be rated with a positive reputation.
%		They define five main roles:
%			social information provider,
%			interactivity role,
%			content provider,
%			administrative feedback,
%			and longevity role.
%		All of them oriented to promote an information-sharing society.
%		Finally,
%			the entity’s overall reputation is calculated as a weighted aggregation of the degree of fulfillment of each role.
%		These weights are dependent on the specific society,
%			and the society has a centralized mechanism that calculates and disseminate these reputation values,
%			and monitors the society.

%		2.3.19
%		Reputation Quotient The Reputation Quotient [48],
%			[49] tries to obtain data on a company’s reputation from the point of view of the general public,
%			customers,
%			employees,
%			suppliers and investors.
%		The model measures perceptions of an organization in terms of social expectations of dimensions such as products and services,
%			vision and leadership,
%			workplace environment and social responsibility.

%		2.3.20
%		FIRE In the FIRE model [124],
%			trust is evaluated based on a different number of information sources:
%			Interaction Trust (IT),
%			that is built from the self-experience of an entity with the other entities; 
%				Witness Reputation (WR) that is based on the direct observation of an entity’s behavior by some third-party agent; Certified Reputation (CR),
%			one of the novelties in the FIRE model,
%			that consists of certified references disclosed by third-party agents; and Role-based Trust (RT),
%			which models the trust across predefined role-based relationships between two entities.
%		The significance of each component in the trust calculation algorithm is adjusted according to changes in the environment.
%		Each component owns a trust algorithm with relevant rating weight function to determine the quality of ratings tailored to its responsibility.
%		Thus,
%			the weighting algorithm for IT is based on the age of ratings whereas WR and CR have to take the credibility of rating into account as well.
%		Credibility is based on a filtering mechanism that identifies inaccurate reports and penalizes misbehaving entities.

%		2.3.21
%		PeerTrust PeerTrust is a trust model [125] with specific characteristics for peer-to-peer e-commerce communities.
%		It uses several factors to calculate the reputation values of the entities (peers): 
%			feedback which is a judgment of other peers regarding target peer; feedback scope,
%			such as the number of transactions the peer experienced with others; 
%				a credibility factor to evaluate the honesty of feedback sources; 
%				transaction context factor such as time and size of transactions; and community context factor.
%		This model proposes an innovative composite trust metric that incorporates the 
%			described parameters to enhance accuracy and reliability of predicted trustworthiness.

%		2.3.23
%		SPIRIT The SPIRIT model [126] can be applied to survey Corporate Reputation from the perspective of customers,
%			employees,
%			suppliers,
%			investors and community groups.
%		It measures Corporate Reputation in terms of the experience,
%			feelings and intentions of stakeholders towards a business.

%		2.3.32
%		Distributed Reputation-based Beacon Trust System 
%			This model was presented by Srinivasan and Teitelbaum [136] 
%			It focuses on keeping the network performance through detecting malicious beacon nodes.
%		Each beacon node monitors and provides information about malfunction behaviors of beacons that are one hope from them.
%		Therefore,
%			nodes can choose to trust in a specific beacon based on this information.
%		They use a voting approach to calculate this trust value.
%		The voting process is based on the reputation tables of each node,
%			that are generated by processing the reputation tables of the close beacon nodes.

%		2.3.30
%		Bayesian Reputation System Bayesian Reputation System (BRS) was proposed by Jøsang et al [132].
%		It supports both binomial and multinomial rating models to allow rating supply happening in different levels.
%		Mathematically,
%			multinomial BRS is based on computing reputation scores by statistically updating the Dirichlet Probability Density Function (PDF) [133],
%			[134].
%		In this context,
%			entities are allowed to rate other entities within any level from a set of predefined rating levels.
%		In contrast,
%			in binomial BRS which is based on Beta Distribution,
%			the agents can only provide binary ratings for the others.
%		Both systems use the same principle to compute the expected reputation scores:
%			combining previous interaction records with new ratings.
%		Besides,
%			in order to deal with dynamism in the participant’s behavior,
%			BRS provides a longevity factor which determines the expiry time of the old ratings and gives greater weight to more recent ones.

%		2.3.31
%		Reputation-based Framework for High Integrity Sensor Networks RFSN was proposed by Ganeriwal and Srivastava [135].
%		It classifies the actions as cooperative and non-cooperative.
%		It uses direct and indirect information,
%			the behavior of the node is decided upon a global threshold.
%		If the trust value is below this threshold, the node is considered a non-cooperative node,
%			any contact from the rest of the network nodes is avoided.
%		The network propagates only positive reputation information in order to avoid some WSN specific attacks such as bad-mouthing attacks.
%		Finally,
%			an aging factor in introduced to give more weight to recent interactions.

%		2.3.26
%		TRAVOS The TRAVOS (Trust and Reputation model for Agent-based Virtual Organizations) 
%			system [128] is developed to ensure high-quality interaction between the entities of a large open system.
%		It uses two information sources to calculate the reputation of the entities:
%			Direct Interaction and Witness Observation.
%		However,
%			this model relies greatly on its direct experiences and refuses to combine others’ opinions unless they are really required.
%		For this purpose,
%			it provides a confidence metric to determine whether the direct experiences are sufficient to make an acceptable review to a particular entity or not.
%		If not,
%			it disseminates queries to obtain additional observations from other witnesses who claim to have had previous interaction with that certain entity.

%		In Trust and Reputation Systems,
%			network users try to calculate the reliability and trustworthiness of other users based on their own experiences and that of others.
%		Boykin et al. [3] proposed an automatic email ranking system based on trust and reputation algorithms.
%		MailRank [4] is a spam detection system based on trust and reputation scheme to classify email addresses

%		%previous direct interaction
%		At the same time,
%			another team of researchers suggested a model where trust is measured from the performance of previous direct interaction with a user
%				as well as the direct interaction and asking trusted users to recommend other users [Esfandiari and Chandrasekharan (2001)].

%		%direct experiences
%		In one proposed model [Yu and Singh (2001)],
%			the trustworthiness of a user is calculated based on direct experience with that user as well as the belief rating of her neighbors.

%		%peer voting
%		Both XRep [26] and X2 Rep [27] extend the work in [25] by additionally computing object reputations based on weighted peer voting.

%		%reputation values *********
%		Moreton and Twigg [28] proposed the Stamp algorithm,
%			where peers issue stamps as virtual currency for each interaction,
%			the value of each peer’s stamps is maintained by exchange rates that act as reputation values.

%		%experience
%		The works in [13],[14],[15] let a peer evaluate others’ trustworthiness based on its experience.
%		Sorcery [16] lets clients utilize the overlapping voting histories of both their 
%			friends and the content providers to judge whether a content provider is a colluder.

All previous work didn't take into consideration the topological aspect of interactions to measure social vulnerabilities of users.
The closest study to our approach is that presented in \cite{zeng_trustaware_2014}.
%The authors present a model for
%This model is based on 
However,
	this solution doesn't study the social interaction environment of users and the potential information leakage through a vulnerable social environment.
In this paper,
	we study the impact of trusting vulnerable users in preserving the privacy of all users in the communication network.

%For our best knowledge,
%	it does not exist a study that
%In this regard,
%	this is the first paper that 

