\section{Related work} \label{sec:Related work}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Research categories %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To evaluate the privacy risk of social network users,
	trust metrics are used to measure the extent to which users can be trusted.
Trust metrics can be classified into two main categories:
	global and local trust metrics.
%Local trust metrics 
Local trust metrics compute trust values that are dependent on the target user.
They take into account the very personal and subjective views of the users.
They predict different values of trust for every single user based on their own experience.
%Global trust metrics 
Global trust metrics,
	on the other hand,
	predict a global reputation value for each node,
	based on both the experience of all other users and the topology of the social network.

%Protect_U & Privacy Wizard
Much work has focused on adapting existing privacy settings to the users profile,
	for example,
	the machine learning techniques used in Protect\_U \cite{gandouz_protect_2012} allow recommending privacy settings based on trustworthy friends.
Protect\_U analyzes the existing privacy settings and ranks them under four risk levels:
	Low Risk,
	Medium Risk,
	Risky and Critical.
The system then suggests personalized recommendations to allow users to make their accounts safer.
In order to achieve this,
	it draws upon two protection models:
	local and community-based.
The first model uses the visibility of users profile information to suggest recommendations.
The second model searches trustworthy friends to encourage them to help improve the safety of their friends account.

%Social Market
Despite a large amount of work on social trust,
	a decentralized interest-based marketplace is built for the first time in SocialMarket \cite{frey_social_2011},
	authors of this framework propose the use of trust relationships to build their decentralized interest-based marketplace.
%9 TAPE
In contrast,
	TAPE framework developed by Zeng et al. \cite{yongbozeng_study_2015} tried to solve the privacy quantification problem \cite{gundecha_exploiting_2011} from a different angle.
First,
	they calculate the privacy trust score of each user to know how likely a friend could reveal or preserve others’ personal information.
Next,
	they propose an information diffusion process \cite{fang_privacy_2010}.
The most important contribution made by TAPE framework \cite{yongbozeng_study_2015} is in considering information diffusion to reveal privacy leakage in communication.

%9
Zeng and Xing \cite{zeng_trustaware_2014}
	studied the maximization of users relationships by making trustful friends without leaking their private information to unwanted parties.
The authors propose a security risk estimation framework to deal with such a problem.
The framework proposed is composed of two parts,
	the calculation of Individual Privacy Leakage Probability (IPLP) and the Relationship Privacy Leakage Probability (RPLP).
%Relationship Privacy Leakage Probability considers the factors of relationship strength and interactive behaviors.
Two vectors namely privacy protection awareness (PPA) and privacy protection trust (PPT) are proposed in this paper to estimate IPLP.

%%Ostra
%Ostra \cite{mislove_ostra_2008} utilizes a trust relationship to thwart unwanted communication,
%	where the number of a user’s trust relationships is used to limit the number of unwanted communications he can produce.
%Ostra utilizes the existing trust relationship among users to charge the senders of unwanted messages and thus block spam.
%It relies on existing trust networks to connect senders and receivers via chains of a pair-wise trust relationship,
%	they use a pair-wise link-based credit scheme to impose a cost on the originator of the unwanted communication.
%Unfortunately,
%	the scalability of this system stays uncertain as it employs a per-link credit scheme.

%8
Gundecha et al. \cite{gundecha_exploiting_2011} propose an advantageous approach to the problem of identifying a user’s vulnerable friends.
%Vulnerability is somewhat contagious in this context.
The approach proposed differs from existing work by integrating a vulnerability-centered approach.
On most online social networks (OSN),
	a mole of work addressed the problem of protecting user's individual attributes only,
	however,
	few works address the problem of protecting users relationships from vulnerable friends.
%Unfriending vulnerable friends in our work can help protect users against privacy issues and at least make them conscious about the vulnerability of their interaction.

%LENS Leveraging Social Networking and Trust to Prevent Spam Transmission
Another example that consolidates our intention to build our privacy awareness framework is called LENS \cite{hameed_lens_2011}.
Hameed \cite{hameed_lens_2011} proposed a novel spam protection system that maximizes the number of trusted nodes who send only trusted emails,
	only emails to a node that have been allowed by these trusted nodes can be sent through the network.
The authors proposed using trust and reputation systems to detect whether a user is trustful or not.

%SocialEmail
SocialEmail \cite{tran_social_2010} is a trust by design communication system,
	it considers trust as an integral part of the communication system.
SocialEmail rank trust paths to rate the messages,
	these last ones are routed through existing friendship links that are weighted with different trust level.
This gives each email recipient an overview of the trustworthiness of path taken by a message to reach him.
In contrast,
	such methods are not sufficiently effective in dealing with legitimate emails from senders outside SocialEmail.

%Social interactions
Social interactions allow users exchanging messages with other users easily and quickly.
	xiang et al. \cite{xiang_modeling_2010} proposed a social interaction as an indicator of interpersonal tie strength.
As a consequence,
	an unsupervised model has been developed to estimate the relationship strength from their interaction activity \cite{xiang_modeling_2010}.
Such methods could extract the level of trust between interlocutors based on the relationship strength between them.
However,
	this application is not designed to be automated,
	users must manually score other users, score messages or create whitelists.

Vidyalakshmi et al. \cite{b.s._privacy_2015} proposed a privacy control framework for information dispersal on social networks,
	they use the quadratic form of bezier curve to arrive at privacy scores for friends,
	they use the communication information for pre-sorting friends which is lacking in \cite{vidyalakshmi_privacy_2015}.
Similarly,
	Akcora et al. \cite{akcora_risks_2012} develop a graph-based approach and a risk model to learn risk labels of strangers,
	the intuition of such an approach is that risky strangers are more likely to violate privacy constraints.

Privacy Index (PIDX) proposed in \cite{nepali_sonet_2013} is a measure of a user’s privacy exposure in a social network.
PIDX is a numerical value between 0 and 100 with a high value indicating high privacy risk in social networks.
An attribute’s privacy impact factor is a ratio of its privacy impact to full privacy disclosure.
Thus,
	an attribute’s privacy impact has a value between 0 and 1.
They consider the privacy impact factor for full privacy disclosure is 1.

%Privacy Wizard
Fang and Le Fevre \cite{fang_privacy_2010} proposed a Privacy Wizard to help users grant privileges to their friends.
It automatically configures users' privacy settings.
The wizard asks users to first assign trust labels to selected friends.
The wizard is then training to classify tagged friends based on both profile information and labels assigned by users themselves.
Ones this step is finished,
	the wizard is now able to assign new labels to unlabeled friends based only on their profile information.
%Risk score
In a similar way,
	some studies \cite{maximilien_privacyasaservice_2009} propose a methodology to quantify the vulnerability of user’s privacy settings.
A risk score reveals to users how far their privacy settings are from those of other users.
However,
	it does not help users refine their settings in order to achieve a more acceptable configuration.

Abdul-Rahman and Hailes \cite{abdul-rahman_supporting_2000}
	proposed a trust model with virtual communities and artificial autonomous agents.
The model defines a direct trust and a recommender trust.
Trust can only have discrete labeled values,
	namely Very Trustworthy,
	Trustworthy,
	Untrustworthy,
	and,
	Very Untrustworthy for direct trust,
	and Very good,
	good,
	bad and,
	very bad for recommender trust.
The difference between the two ratings from different entities can be computed as a semantic distance that can be used to adjust further recommendations.
The combination of ratings is done as a weighted sum,
	where the weights depend on the recommender trust.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Related work position %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All previous work didn't take into consideration the topological aspect of interactions to measure social vulnerabilities of users.
The closest study to our approach is that presented in \cite{zeng_trustaware_2014}.
However,
	this solution doesn't study the impact of having interactions with vulnerable users.
In this paper,
	we study the impact of trusting vulnerable users in preserving the privacy of all users in the communication network.

%For our best knowledge,
%	it does not exist a study that
%In this regard,
%	this is the first paper that 

